{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix  \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import lightgbm as lgbm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('dataset/train.csv')\n",
    "train.fillna('', inplace=True)\n",
    "y = train['is_duplicate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载特征\n",
    "fs_basic = pd.read_csv('feature_store/train_feature_basic.csv')\n",
    "fs_fuzz = pd.read_csv('feature_store/train_feature_fuzz.csv')\n",
    "fs_w2v_gnews = pd.read_csv('feature_store/train_feature_w2v_gnews.csv')\n",
    "fs_tfidf = pd.read_csv('feature_store/train_feature_tfidf.csv')\n",
    "fs_w2v_glove = pd.read_csv('feature_store/train_feature_w2v_glove.csv')\n",
    "fs_graph = pd.read_csv('feature_store/train_feature_graph.csv')\n",
    "fs_freq = pd.read_csv('feature_store/train_feature_freq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 填充缺失值\n",
    "fs_w2v_gnews.fillna(0,inplace=True)\n",
    "fs_w2v_glove.fillna(0,inplace=True)\n",
    "fs_tfidf.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack((fs_basic, fs_fuzz, fs_w2v_gnews, fs_tfidf, fs_w2v_glove, fs_freq, fs_graph))\n",
    "# 处理异常值\n",
    "X[np.isinf(X)] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM 算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds.\n",
      "[200]\tvalid's binary_logloss: 0.280147\n",
      "[400]\tvalid's binary_logloss: 0.262643\n",
      "[600]\tvalid's binary_logloss: 0.257706\n",
      "[800]\tvalid's binary_logloss: 0.255385\n",
      "[1000]\tvalid's binary_logloss: 0.253837\n",
      "[1200]\tvalid's binary_logloss: 0.25279\n",
      "[1400]\tvalid's binary_logloss: 0.251856\n",
      "[1600]\tvalid's binary_logloss: 0.251167\n",
      "[1800]\tvalid's binary_logloss: 0.250642\n",
      "[2000]\tvalid's binary_logloss: 0.250081\n",
      "[2200]\tvalid's binary_logloss: 0.249656\n",
      "[2400]\tvalid's binary_logloss: 0.249262\n",
      "[2600]\tvalid's binary_logloss: 0.248836\n",
      "[2800]\tvalid's binary_logloss: 0.24853\n",
      "[3000]\tvalid's binary_logloss: 0.248289\n",
      "[3200]\tvalid's binary_logloss: 0.248069\n",
      "Early stopping, best iteration is:\n",
      "[3208]\tvalid's binary_logloss: 0.248056\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary', # 目标函数\n",
    "    'metric': 'binary_logloss', # 设置提升类型\n",
    "    'num_leaves': 47, # 叶子节点数\n",
    "    'learning_rate': 0.02, # 学习速率\n",
    "    'feature_fraction': 0.75, # 建树的特征选择比例\n",
    "    'bagging_fraction': 0.8, # 建树的样本采样比例\n",
    "    'bagging_freq': 5, # k 意味着每 k 次迭代执行bagging\n",
    "    'verbose': 0, # <0 显示致命的, =0 显示错误 (警告), >0 显示信息\n",
    "    'save_binary': True,\n",
    "    'min_data_in_leaf': 100, \n",
    "    'max_bin': 1023,\n",
    "}\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(mm_X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "lgbm_train = lgbm.Dataset(X_train, y_train, feature_name=feature_names)\n",
    "lgbm_valid = lgbm.Dataset(X_test, y_test, reference=lgbm_train, feature_name=feature_names)\n",
    "\n",
    "bst = lgbm.train(params, lgbm_train, num_boost_round=5000, \n",
    "                 valid_sets=lgbm_valid, valid_names='valid',\n",
    "                 early_stopping_rounds=20, verbose_eval=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ai]",
   "language": "python",
   "name": "conda-env-ai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
